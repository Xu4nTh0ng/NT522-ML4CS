{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Xây dựng trình phát hiện phần mềm độc hại bằng phân tích tĩnh**"
      ],
      "metadata": {
        "id": "EJIqu6yOQ6M2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B1: Tạo list các mẫu và gán nhãn cho chúng"
      ],
      "metadata": {
        "id": "HkqyrSxaRCqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PezbzM0HIWFZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "directories_with_labels = [(\"/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples\", 0), \n",
        "                           (\"/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Malicious PE Samples\", 1)]\n",
        "list_of_samples = []\n",
        "labels = []\n",
        "for dataset_path, label in directories_with_labels:\n",
        "  samples = [f for f in listdir(dataset_path)]\n",
        "  for sample in samples:\n",
        "    file_path = os.path.join(dataset_path, sample)\n",
        "    list_of_samples.append(file_path)\n",
        "    labels.append(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B2: Tạo list các mẫu và gán nhãn cho chúng"
      ],
      "metadata": {
        "id": "xCsG8wV0RNVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "samples_train, samples_test, labels_train, labels_test = train_test_split(list_of_samples, labels, test_size=0.3, stratify=labels, random_state=11)"
      ],
      "metadata": {
        "id": "OgsrSjWsIv95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B3: Các hàm lấy thuộc tính"
      ],
      "metadata": {
        "id": "LSOfFsfGRn_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install collection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJWt7901I0eU",
        "outputId": "e3aee596-aa61-41ca-bf63-fbf89d1c210b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: collection in /usr/local/lib/python3.9/dist-packages (0.1.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pefile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh9-y2uuI3or",
        "outputId": "16dc94d5-4f78-4d98-dc2f-76661a83b8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pefile\n",
            "  Downloading pefile-2023.2.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pefile\n",
            "Successfully installed pefile-2023.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file_path):\n",
        "  with open(file_path, \"rb\") as bin_file:\n",
        "    data = bin_file.read()\n",
        "    return data\n",
        "def byte_seq_to_Ngrams(byte_seq, N_par):\n",
        "  Ngrams_par = ngrams(byte_seq, N_par)\n",
        "  return list(Ngrams_par)\n",
        "def bin_file_to_Ngrams_count(file_path, N_par):\n",
        "  file_seq = read_file(file_path)\n",
        "  file_Ngrams = byte_seq_to_Ngrams(file_seq, N_par)\n",
        "  return collections.Counter(file_Ngrams)\n",
        "def get_Ngrams_features_from_samples(sample, K1_most_freq_Ngrams_list):\n",
        "  K1 = len(K1_most_freq_Ngrams_list)\n",
        "  feature_vector = K1 * [0]\n",
        "  file_Ngrams = bin_file_to_Ngrams_count(sample, N)\n",
        "  for i in range(K1):\n",
        "    feature_vector[i] = file_Ngrams[K1_most_freq_Ngrams_list[i]]\n",
        "  return feature_vector\n",
        "def preprocess_imports(list_of_DLLs):\n",
        "  \"\"\" Normalize the name of the imports of a PE file. \"\"\"\n",
        "  temp = [x.decode().split(\".\")[0].lower() for x in list_of_DLLs] # View the transforming of below example\n",
        "  return \" \".join(temp)\n",
        "def get_imports(pe):\n",
        "  \"\"\" Get a list of the imports of a PE file \"\"\"\n",
        "  list_of_imports = []\n",
        "  for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
        "    list_of_imports.append(entry.dll)\n",
        "  return preprocess_imports(list_of_imports)\n",
        "def get_section_names(pe):\n",
        "  \"\"\" Get a list of the section names of a PE file \"\"\"\n",
        "  list_of_sections = []\n",
        "  for sect in pe.sections:\n",
        "    normalized_name = sect.Name.decode().replace(\"\\x00\", \"\").lower()\n",
        "    list_of_sections.append(normalized_name)\n",
        "  return \"\".join(list_of_sections)"
      ],
      "metadata": {
        "id": "x9_75H-hJXKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B4: Chọn 100 thuộc tính phổ biến với 2-grams"
      ],
      "metadata": {
        "id": "GwOgFrMaR1AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2\n",
        "Ngram_counts_all = collections.Counter([])\n",
        "for sample in samples_train:\n",
        "  Ngram_counts_all += bin_file_to_Ngrams_count(sample, N)\n",
        "K1 = 100\n",
        "K1_most_frequent_Ngrams = Ngram_counts_all.most_common(K1)\n",
        "K1_most_frequent_Ngrams_list = [x[0] for x in K1_most_frequent_Ngrams]"
      ],
      "metadata": {
        "id": "6U2EWvxqI3k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B5: Trích xuất số lượng N-grams count, section names, imports và số lượng sections\n",
        "của mỗi mẫu trong train-test"
      ],
      "metadata": {
        "id": "cgvoUfW5R38i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imports_corpus_train = []\n",
        "num_sections_train = []\n",
        "section_names_train = []\n",
        "Ngram_features_list_train = []\n",
        "y_train = []\n",
        "for i in range(len(samples_train)):\n",
        "  sample = samples_train[i]\n",
        "  try:\n",
        "    NGram_features = get_Ngrams_features_from_samples(sample,K1_most_frequent_Ngrams_list)\n",
        "    pe = pefile.PE(sample)\n",
        "    imports = get_imports(pe)\n",
        "    n_sections = len(pe.sections)\n",
        "    sec_names = get_section_names(pe)\n",
        "    imports_corpus_train.append(imports)\n",
        "    num_sections_train.append(n_sections)\n",
        "    section_names_train.append(sec_names)\n",
        "    Ngram_features_list_train.append(NGram_features)\n",
        "    y_train.append(labels_train[i])\n",
        "  except Exception as e:\n",
        "    print(sample + \":\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wva-M88FOPhF",
        "outputId": "ceb33922-8db6-43af-a3a2-cb34194c85e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CExecSvc.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/ADSchemaAnalyzer.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/c2wtshost.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/BootExpCfg.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/dplaysvr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/evntcmd.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/hvsirdpclient.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/iissetup.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/ldp.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/lpr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/InspectVhdDialog.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/iisreset.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/InetMgr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Malicious PE Samples/wirelesskeyview.exe:\n",
            "'utf-8' codec can't decode byte 0xff in position 1: invalid start byte\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/cmak.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/eshell.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/InetMgr6.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/dsacls.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/bash.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/inetinfo.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/hvsirpcd.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/adamuninstall.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/appcmd.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/ldifde.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/hcsdiag.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/dsmgmt.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/csvde.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/aspnetca.exe:\n",
            "'DOS Header magic not found.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B6: Sử dụng hàm băm tfidf để chuyển imports, section names từ văn bản thành dạng\n",
        "số"
      ],
      "metadata": {
        "id": "meSxnJSfR9jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "imports_featurizer = Pipeline(\n",
        "[\n",
        "(\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1,2))),\n",
        "(\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
        "]\n",
        ")\n",
        "section_names_featurizer = Pipeline(\n",
        "[\n",
        "(\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1, 2))),\n",
        "(\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
        "]\n",
        ")\n",
        "imports_corpus_train_transformed = imports_featurizer.fit_transform(imports_corpus_train)\n",
        "section_names_train_transformed = section_names_featurizer.fit_transform(section_names_train)"
      ],
      "metadata": {
        "id": "bwMvrSpPLk3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B7: Kết hợp các vector thuộc tính thành 1 mảng"
      ],
      "metadata": {
        "id": "KhAKH_A0Sdqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "X_train = hstack(\n",
        "[\n",
        "  Ngram_features_list_train,\n",
        "  imports_corpus_train_transformed,\n",
        "  section_names_train_transformed,\n",
        "  csr_matrix(num_sections_train).transpose(),\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "NKQUBJ_QLx4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B8: Ta huấn luyên bằng phân loại Random Forest cho tập train"
      ],
      "metadata": {
        "id": "sybOQDKTSUmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "hR04bBdyL36C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B9: Thu thập các thuộc tính của tập test, giống như tập huấn luyện"
      ],
      "metadata": {
        "id": "iziI86eUSljY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imports_corpus_test = []\n",
        "num_sections_test = []\n",
        "section_names_test = []\n",
        "Ngram_features_list_test = []\n",
        "y_test = []\n",
        "for i in range(len(samples_test)):\n",
        "  file = samples_test[i]\n",
        "  try:\n",
        "    NGram_features = get_Ngrams_features_from_samples(sample, K1_most_frequent_Ngrams_list)\n",
        "    pe = pefile.PE(file)\n",
        "    imports = get_imports(pe)\n",
        "    n_sections = len(pe.sections)\n",
        "    sec_names = get_section_names(pe)\n",
        "    imports_corpus_test.append(imports)\n",
        "    num_sections_test.append(n_sections)\n",
        "    section_names_test.append(sec_names)\n",
        "    Ngram_features_list_test.append(NGram_features)\n",
        "    y_test.append(labels_test[i])\n",
        "  except Exception as e:\n",
        "    print(sample + \":\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmSZgJHGL6mh",
        "outputId": "ea08d5d5-b5a3-40f3-a79d-c6f33b9eaebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'PE' object has no attribute 'DIRECTORY_ENTRY_IMPORT'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/drive/MyDrive/Machine Learning/Lab 2/Samples/Benign PE Samples/CompMgmtLauncher.exe:\n",
            "'DOS Header magic not found.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "M6EUYbFeQCFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B10. Ta chuyển đổi vector từ thuộc tính test, và kiểm tra kết quả của trình phân loại"
      ],
      "metadata": {
        "id": "8M7-QpblSq_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import_corpus_test_transformed = imports_featurizer.transform(imports_corpus_test)\n",
        "sect_names_test_transformed = imports_featurizer.transform(section_names_test)\n",
        "X_test = hstack(\n",
        "    [\n",
        "        Ngram_features_list_test,\n",
        "        import_corpus_test_transformed,\n",
        "        sect_names_test_transformed, \n",
        "        csr_matrix(num_sections_test).transpose()\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "FrbCpoVtPmE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Kết quả của trình phân loại: \")\n",
        "print(clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBQylj8kQRZ5",
        "outputId": "a441551a-8aa6-42c8-9d08-6f40ba6d16b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kết quả của trình phân loại: \n",
            "0.9801980198019802\n"
          ]
        }
      ]
    }
  ]
}